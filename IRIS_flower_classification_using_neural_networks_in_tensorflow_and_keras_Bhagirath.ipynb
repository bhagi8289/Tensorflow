{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa-dagTbwivV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54ead265-627b-43f8-cbe6-6e4e04cb71bb"
      },
      "source": [
        "#!pip install --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nreQHMOTmuJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oDvD1KwxQY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "635f7a1b-fdcd-4185-b10a-03c0826b3d60"
      },
      "source": [
        "import tensorflow as tf\n",
        "from  tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avitxj-_nT1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Array display should not be truncated\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "np.set_printoptions(precision=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "#np.set_printoptions(suppress=True,formatter={'float_kind':'{:0.2f}'.format}) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymUAWaAxyW5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :4]  # we take the first four features.\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yuawfQ3sV58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e2cf76c5-7379-4e83-ae27-2230bb797efa"
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "revynxUUsb31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc30483b-b1cf-4550-9579-2643cbcff1c9"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isGYn1Knyccg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f4ceea0-73bc-40e7-ab79-4686ef74cfef"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro2Aix8jsbCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUWcsk3XyfiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f61fdd1-1c6e-4921-995f-ea99c988ac67"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmR-2LDeMt9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "420659fc-da7f-4fb6-c32e-854c48658236"
      },
      "source": [
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mKL_FQM49v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_encoded = np_utils.to_categorical(encoded_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRwiadXrNQz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2110ef66-96a3-4453-b490-2260b4004694"
      },
      "source": [
        "y_encoded"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmWUCvCvNG0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvMJNOPkJb_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y_encoded,test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3QnrT_jyhCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(units=16, activation='relu',input_shape=(135,2)))\n",
        "model.add(Dense(units=16, activation='relu',input_dim=4))\n",
        "model.add(Dense(units=12, activation='relu'))\n",
        "model.add(Dense(units=3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAWfOAkaJyNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dec8d1cc-cded-4e5f-abc3-2d79b3949ce5"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndx29jrIz-xR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "55db1d8c-834c-442b-83a3-ef580f4de0d7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                204       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 39        \n",
            "=================================================================\n",
            "Total params: 323\n",
            "Trainable params: 323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7auJbfSu0dNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1b813ea-e5fd-45d2-b514-b2c6be62fc52"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, batch_size=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 135 samples\n",
            "Epoch 1/100\n",
            "135/135 [==============================] - 0s 3ms/sample - loss: 1.5457 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "135/135 [==============================] - 0s 383us/sample - loss: 1.0684 - accuracy: 0.3630\n",
            "Epoch 3/100\n",
            "135/135 [==============================] - 0s 370us/sample - loss: 0.9541 - accuracy: 0.4593\n",
            "Epoch 4/100\n",
            "135/135 [==============================] - 0s 369us/sample - loss: 0.8765 - accuracy: 0.5630\n",
            "Epoch 5/100\n",
            "135/135 [==============================] - 0s 352us/sample - loss: 0.8068 - accuracy: 0.8963\n",
            "Epoch 6/100\n",
            "135/135 [==============================] - 0s 356us/sample - loss: 0.7395 - accuracy: 0.7630\n",
            "Epoch 7/100\n",
            "135/135 [==============================] - 0s 371us/sample - loss: 0.6749 - accuracy: 0.9111\n",
            "Epoch 8/100\n",
            "135/135 [==============================] - 0s 383us/sample - loss: 0.6088 - accuracy: 0.8815\n",
            "Epoch 9/100\n",
            "135/135 [==============================] - 0s 391us/sample - loss: 0.5524 - accuracy: 0.8593\n",
            "Epoch 10/100\n",
            "135/135 [==============================] - 0s 362us/sample - loss: 0.5080 - accuracy: 0.9481\n",
            "Epoch 11/100\n",
            "135/135 [==============================] - 0s 338us/sample - loss: 0.4659 - accuracy: 0.9407\n",
            "Epoch 12/100\n",
            "135/135 [==============================] - 0s 335us/sample - loss: 0.4308 - accuracy: 0.9481\n",
            "Epoch 13/100\n",
            "135/135 [==============================] - 0s 355us/sample - loss: 0.4039 - accuracy: 0.9185\n",
            "Epoch 14/100\n",
            "135/135 [==============================] - 0s 346us/sample - loss: 0.3812 - accuracy: 0.9556\n",
            "Epoch 15/100\n",
            "135/135 [==============================] - 0s 368us/sample - loss: 0.3650 - accuracy: 0.9481\n",
            "Epoch 16/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.3494 - accuracy: 0.9481\n",
            "Epoch 17/100\n",
            "135/135 [==============================] - 0s 398us/sample - loss: 0.3304 - accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.3181 - accuracy: 0.9111\n",
            "Epoch 19/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.3027 - accuracy: 0.9556\n",
            "Epoch 20/100\n",
            "135/135 [==============================] - 0s 361us/sample - loss: 0.2909 - accuracy: 0.9556\n",
            "Epoch 21/100\n",
            "135/135 [==============================] - 0s 354us/sample - loss: 0.2773 - accuracy: 0.9704\n",
            "Epoch 22/100\n",
            "135/135 [==============================] - 0s 320us/sample - loss: 0.2656 - accuracy: 0.9481\n",
            "Epoch 23/100\n",
            "135/135 [==============================] - 0s 408us/sample - loss: 0.2584 - accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "135/135 [==============================] - 0s 386us/sample - loss: 0.2456 - accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "135/135 [==============================] - 0s 345us/sample - loss: 0.2382 - accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "135/135 [==============================] - 0s 346us/sample - loss: 0.2310 - accuracy: 0.9481\n",
            "Epoch 27/100\n",
            "135/135 [==============================] - 0s 324us/sample - loss: 0.2213 - accuracy: 0.9556\n",
            "Epoch 28/100\n",
            "135/135 [==============================] - 0s 369us/sample - loss: 0.2210 - accuracy: 0.9481\n",
            "Epoch 29/100\n",
            "135/135 [==============================] - 0s 349us/sample - loss: 0.2077 - accuracy: 0.9481\n",
            "Epoch 30/100\n",
            "135/135 [==============================] - 0s 373us/sample - loss: 0.1981 - accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.1905 - accuracy: 0.9556\n",
            "Epoch 32/100\n",
            "135/135 [==============================] - 0s 302us/sample - loss: 0.1853 - accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "135/135 [==============================] - 0s 332us/sample - loss: 0.1829 - accuracy: 0.9481\n",
            "Epoch 34/100\n",
            "135/135 [==============================] - 0s 396us/sample - loss: 0.1760 - accuracy: 0.9481\n",
            "Epoch 35/100\n",
            "135/135 [==============================] - 0s 318us/sample - loss: 0.1698 - accuracy: 0.9556\n",
            "Epoch 36/100\n",
            "135/135 [==============================] - 0s 401us/sample - loss: 0.1647 - accuracy: 0.9778\n",
            "Epoch 37/100\n",
            "135/135 [==============================] - 0s 384us/sample - loss: 0.1583 - accuracy: 0.9704\n",
            "Epoch 38/100\n",
            "135/135 [==============================] - 0s 372us/sample - loss: 0.1569 - accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "135/135 [==============================] - 0s 367us/sample - loss: 0.1563 - accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "135/135 [==============================] - 0s 366us/sample - loss: 0.1492 - accuracy: 0.9704\n",
            "Epoch 41/100\n",
            "135/135 [==============================] - 0s 341us/sample - loss: 0.1452 - accuracy: 0.9704\n",
            "Epoch 42/100\n",
            "135/135 [==============================] - 0s 327us/sample - loss: 0.1440 - accuracy: 0.9704\n",
            "Epoch 43/100\n",
            "135/135 [==============================] - 0s 377us/sample - loss: 0.1390 - accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "135/135 [==============================] - 0s 354us/sample - loss: 0.1373 - accuracy: 0.9704\n",
            "Epoch 45/100\n",
            "135/135 [==============================] - 0s 345us/sample - loss: 0.1353 - accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "135/135 [==============================] - 0s 399us/sample - loss: 0.1420 - accuracy: 0.9556\n",
            "Epoch 47/100\n",
            "135/135 [==============================] - 0s 398us/sample - loss: 0.1278 - accuracy: 0.9630\n",
            "Epoch 48/100\n",
            "135/135 [==============================] - 0s 349us/sample - loss: 0.1304 - accuracy: 0.9630\n",
            "Epoch 49/100\n",
            "135/135 [==============================] - 0s 334us/sample - loss: 0.1236 - accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "135/135 [==============================] - 0s 355us/sample - loss: 0.1234 - accuracy: 0.9630\n",
            "Epoch 51/100\n",
            "135/135 [==============================] - 0s 358us/sample - loss: 0.1185 - accuracy: 0.9704\n",
            "Epoch 52/100\n",
            "135/135 [==============================] - 0s 371us/sample - loss: 0.1227 - accuracy: 0.9630\n",
            "Epoch 53/100\n",
            "135/135 [==============================] - 0s 391us/sample - loss: 0.1152 - accuracy: 0.9704\n",
            "Epoch 54/100\n",
            "135/135 [==============================] - 0s 341us/sample - loss: 0.1136 - accuracy: 0.9704\n",
            "Epoch 55/100\n",
            "135/135 [==============================] - 0s 345us/sample - loss: 0.1125 - accuracy: 0.9556\n",
            "Epoch 56/100\n",
            "135/135 [==============================] - 0s 340us/sample - loss: 0.1075 - accuracy: 0.9556\n",
            "Epoch 57/100\n",
            "135/135 [==============================] - 0s 348us/sample - loss: 0.1098 - accuracy: 0.9704\n",
            "Epoch 58/100\n",
            "135/135 [==============================] - 0s 371us/sample - loss: 0.1047 - accuracy: 0.9704\n",
            "Epoch 59/100\n",
            "135/135 [==============================] - 0s 335us/sample - loss: 0.1058 - accuracy: 0.9704\n",
            "Epoch 60/100\n",
            "135/135 [==============================] - 0s 404us/sample - loss: 0.1110 - accuracy: 0.9556\n",
            "Epoch 61/100\n",
            "135/135 [==============================] - 0s 340us/sample - loss: 0.1171 - accuracy: 0.9556\n",
            "Epoch 62/100\n",
            "135/135 [==============================] - 0s 540us/sample - loss: 0.1112 - accuracy: 0.9630\n",
            "Epoch 63/100\n",
            "135/135 [==============================] - 0s 348us/sample - loss: 0.0966 - accuracy: 0.9630\n",
            "Epoch 64/100\n",
            "135/135 [==============================] - 0s 360us/sample - loss: 0.1120 - accuracy: 0.9630\n",
            "Epoch 65/100\n",
            "135/135 [==============================] - 0s 350us/sample - loss: 0.1083 - accuracy: 0.9630\n",
            "Epoch 66/100\n",
            "135/135 [==============================] - 0s 338us/sample - loss: 0.1059 - accuracy: 0.9556\n",
            "Epoch 67/100\n",
            "135/135 [==============================] - 0s 403us/sample - loss: 0.1013 - accuracy: 0.9556\n",
            "Epoch 68/100\n",
            "135/135 [==============================] - 0s 393us/sample - loss: 0.0962 - accuracy: 0.9556\n",
            "Epoch 69/100\n",
            "135/135 [==============================] - 0s 356us/sample - loss: 0.1036 - accuracy: 0.9704\n",
            "Epoch 70/100\n",
            "135/135 [==============================] - 0s 349us/sample - loss: 0.1046 - accuracy: 0.9556\n",
            "Epoch 71/100\n",
            "135/135 [==============================] - 0s 370us/sample - loss: 0.0989 - accuracy: 0.9630\n",
            "Epoch 72/100\n",
            "135/135 [==============================] - 0s 333us/sample - loss: 0.0957 - accuracy: 0.9778\n",
            "Epoch 73/100\n",
            "135/135 [==============================] - 0s 366us/sample - loss: 0.0897 - accuracy: 0.9630\n",
            "Epoch 74/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.0944 - accuracy: 0.9778\n",
            "Epoch 75/100\n",
            "135/135 [==============================] - 0s 341us/sample - loss: 0.1034 - accuracy: 0.9630\n",
            "Epoch 76/100\n",
            "135/135 [==============================] - 0s 340us/sample - loss: 0.0926 - accuracy: 0.9556\n",
            "Epoch 77/100\n",
            "135/135 [==============================] - 0s 366us/sample - loss: 0.0917 - accuracy: 0.9704\n",
            "Epoch 78/100\n",
            "135/135 [==============================] - 0s 367us/sample - loss: 0.0921 - accuracy: 0.9852\n",
            "Epoch 79/100\n",
            "135/135 [==============================] - 0s 352us/sample - loss: 0.0891 - accuracy: 0.9778\n",
            "Epoch 80/100\n",
            "135/135 [==============================] - 0s 378us/sample - loss: 0.0921 - accuracy: 0.9630\n",
            "Epoch 81/100\n",
            "135/135 [==============================] - 0s 512us/sample - loss: 0.0959 - accuracy: 0.9630\n",
            "Epoch 82/100\n",
            "135/135 [==============================] - 0s 376us/sample - loss: 0.0915 - accuracy: 0.9704\n",
            "Epoch 83/100\n",
            "135/135 [==============================] - 0s 374us/sample - loss: 0.0858 - accuracy: 0.9556\n",
            "Epoch 84/100\n",
            "135/135 [==============================] - 0s 383us/sample - loss: 0.0888 - accuracy: 0.9704\n",
            "Epoch 85/100\n",
            "135/135 [==============================] - 0s 398us/sample - loss: 0.0950 - accuracy: 0.9630\n",
            "Epoch 86/100\n",
            "135/135 [==============================] - 0s 377us/sample - loss: 0.0847 - accuracy: 0.9704\n",
            "Epoch 87/100\n",
            "135/135 [==============================] - 0s 471us/sample - loss: 0.0833 - accuracy: 0.9630\n",
            "Epoch 88/100\n",
            "135/135 [==============================] - 0s 529us/sample - loss: 0.0861 - accuracy: 0.9704\n",
            "Epoch 89/100\n",
            "135/135 [==============================] - 0s 405us/sample - loss: 0.0827 - accuracy: 0.9704\n",
            "Epoch 90/100\n",
            "135/135 [==============================] - 0s 378us/sample - loss: 0.0891 - accuracy: 0.9630\n",
            "Epoch 91/100\n",
            "135/135 [==============================] - 0s 358us/sample - loss: 0.0833 - accuracy: 0.9704\n",
            "Epoch 92/100\n",
            "135/135 [==============================] - 0s 373us/sample - loss: 0.0836 - accuracy: 0.9704\n",
            "Epoch 93/100\n",
            "135/135 [==============================] - 0s 383us/sample - loss: 0.0864 - accuracy: 0.9556\n",
            "Epoch 94/100\n",
            "135/135 [==============================] - 0s 364us/sample - loss: 0.0827 - accuracy: 0.9704\n",
            "Epoch 95/100\n",
            "135/135 [==============================] - 0s 367us/sample - loss: 0.0794 - accuracy: 0.9630\n",
            "Epoch 96/100\n",
            "135/135 [==============================] - 0s 375us/sample - loss: 0.0799 - accuracy: 0.9630\n",
            "Epoch 97/100\n",
            "135/135 [==============================] - 0s 335us/sample - loss: 0.0796 - accuracy: 0.9630\n",
            "Epoch 98/100\n",
            "135/135 [==============================] - 0s 377us/sample - loss: 0.0941 - accuracy: 0.9556\n",
            "Epoch 99/100\n",
            "135/135 [==============================] - 0s 388us/sample - loss: 0.0892 - accuracy: 0.9630\n",
            "Epoch 100/100\n",
            "135/135 [==============================] - 0s 378us/sample - loss: 0.0816 - accuracy: 0.9630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUSz7pPc0ovx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40e625f0-51ca-48a7-a5e3-f83621855da5"
      },
      "source": [
        "_,accuracy = model.evaluate(X_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r15/15 [==============================] - 0s 7ms/sample - loss: 0.0153 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL17-lU0OgVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74077ff9-873e-4eb7-bf86-b42899463e89"
      },
      "source": [
        "model.predict([[5.1, 3.5, 1.4, 0.2]])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS9aOpTbk119",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}